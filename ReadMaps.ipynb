{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import concurrent.futures\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "# Function to parse JSON data and return a list of dictionaries\n",
    "def parse_json_data(data):\n",
    "    rows = []\n",
    "    for obj in data[\"timelineObjects\"]:\n",
    "        if \"activitySegment\" in obj:\n",
    "            segment = obj[\"activitySegment\"]\n",
    "            if \"startLocation\" not in segment or \"endLocation\" not in segment:\n",
    "                continue\n",
    "\n",
    "            start_location = segment[\"startLocation\"]\n",
    "            end_location = segment[\"endLocation\"]\n",
    "            duration = segment[\"duration\"]\n",
    "            activities = segment[\"activities\"]\n",
    "\n",
    "            for activity in activities:\n",
    "                if (\n",
    "                    \"latitudeE7\" in start_location\n",
    "                    and \"longitudeE7\" in start_location\n",
    "                    and \"latitudeE7\" in end_location\n",
    "                    and \"longitudeE7\" in end_location\n",
    "                ):\n",
    "                    row = {\n",
    "                        \"start_latitude\": start_location[\"latitudeE7\"],\n",
    "                        \"start_longitude\": start_location[\"longitudeE7\"],\n",
    "                        \"end_latitude\": end_location[\"latitudeE7\"],\n",
    "                        \"end_longitude\": end_location[\"longitudeE7\"],\n",
    "                        \"start_timestamp\": duration[\"startTimestamp\"],\n",
    "                        \"end_timestamp\": duration[\"endTimestamp\"],\n",
    "                        \"activity_type\": activity[\"activityType\"],\n",
    "                        \"probability\": activity[\"probability\"],\n",
    "                    }\n",
    "                    rows.append(row)\n",
    "        elif \"placeVisit\" in obj:\n",
    "            visit = obj[\"placeVisit\"]\n",
    "            if \"location\" not in visit:\n",
    "                continue\n",
    "            location = visit[\"location\"]\n",
    "            duration = visit[\"duration\"]\n",
    "            if (\n",
    "                \"latitudeE7\" in location\n",
    "                and \"longitudeE7\" in location\n",
    "                and \"startTimestamp\" in duration\n",
    "                and \"endTimestamp\" in duration\n",
    "            ):\n",
    "                row = {\n",
    "                    \"start_latitude\": location[\"latitudeE7\"],\n",
    "                    \"start_longitude\": location[\"longitudeE7\"],\n",
    "                    \"end_latitude\": location[\"latitudeE7\"],\n",
    "                    \"end_longitude\": location[\"longitudeE7\"],\n",
    "                    \"start_timestamp\": duration[\"startTimestamp\"],\n",
    "                    \"end_timestamp\": duration[\"endTimestamp\"],\n",
    "                    \"activity_type\": \"PLACE_VISIT\",\n",
    "                    \"probability\": None,\n",
    "                }\n",
    "                rows.append(row)\n",
    "    return rows\n",
    "\n",
    "def ask_for_directory():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    folder_selected = filedialog.askdirectory()\n",
    "    return folder_selected\n",
    "\n",
    "\n",
    "# Define the paths to search for JSON files\n",
    "\n",
    "\n",
    "def process_json_file(json_file):\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        data = json.load(f)\n",
    "        return parse_json_data(data)\n",
    "\n",
    "selected_folder = ask_for_directory()\n",
    "path_pattern = os.path.join(selected_folder, \"Location History\", \"Semantic Location History\", \"*\", \"*.json\")\n",
    "\n",
    "all_data = []\n",
    "json_files = glob.glob(path_pattern)\n",
    "\n",
    "# Use a ThreadPoolExecutor to process JSON files concurrently\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    results = list(executor.map(process_json_file, json_files))\n",
    "\n",
    "    for result in results:\n",
    "        all_data.extend(result)\n",
    "\n",
    "# Write the data to a CSV file\n",
    "csv_file = \"combined_data.csv\"\n",
    "csv_columns = [\"start_latitude\", \"start_longitude\", \"end_latitude\", \"end_longitude\", \"start_timestamp\", \"end_timestamp\", \"activity_type\", \"probability\"]\n",
    "\n",
    "with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=csv_columns)\n",
    "    writer.writeheader()\n",
    "    for data in all_data:\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import math\n",
    "from collections import Counter\n",
    "from folium.plugins import MarkerCluster\n",
    "from datetime import datetime\n",
    "import folium.utilities as util\n",
    "\n",
    "# Aggregate location data\n",
    "locations = []\n",
    "for row in all_data:\n",
    "    locations.append((row[\"start_latitude\"] / 1e7, row[\"start_longitude\"] / 1e7))\n",
    "    locations.append((row[\"end_latitude\"] / 1e7, row[\"end_longitude\"] / 1e7))\n",
    "\n",
    "# Find the most active locations\n",
    "location_count = Counter(locations)\n",
    "top_locations = location_count.most_common(250)  # Adjust the number to show more or less locations\n",
    "\n",
    "\n",
    "# Create the map centered on the first top location\n",
    "latitude, longitude = top_locations[0][0]\n",
    "map = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    "\n",
    "# Function to compute the circle radius based on the map's zoom level\n",
    "def compute_radius(zoom, count):\n",
    "    base_radius = 10 * math.log(count + 1)\n",
    "    return base_radius * (1 / (1 << (15 - zoom)))\n",
    "\n",
    "# Create a MarkerCluster\n",
    "marker_cluster = MarkerCluster().add_to(map)\n",
    "\n",
    "def convert_to_local_time(timestamp_str):\n",
    "    try:\n",
    "        dt = datetime.strptime(timestamp_str, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "    except ValueError:\n",
    "        dt = datetime.strptime(timestamp_str, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    return dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "# Add bubbles to the map for the most active locations\n",
    "initial_zoom = 12\n",
    "for location, count in top_locations:\n",
    "    lat, lng = location\n",
    "\n",
    "    # Get the row associated with the current location\n",
    "    row = next((row for row in all_data if (row[\"start_latitude\"] / 1e7, row[\"start_longitude\"] / 1e7) == location), None)\n",
    "    if row:\n",
    "        if 'end_timestamp' in row:\n",
    "            start_time = convert_to_local_time(row['start_timestamp'])\n",
    "            end_time = convert_to_local_time(row['end_timestamp'])\n",
    "            activity_type = row['activity_type']\n",
    "        else:\n",
    "            start_time = convert_to_local_time(row['start_timestamp'])\n",
    "            end_time = 'N/A'\n",
    "            activity_type = 'N/A'\n",
    "        activity_type = row[\"activity_type\"]\n",
    "    else:\n",
    "        start_time = \"N/A\"\n",
    "        end_time = \"N/A\"\n",
    "        activity_type = \"N/A\"\n",
    "\n",
    "    popup_text = f\"Location: {lat:.6f}, {lng:.6f}<br>Time: {start_time} - {end_time}<br>Date: {start_time[:10]}<br>Method of travel: {activity_type}\"\n",
    "    popup = folium.Popup(popup_text, max_width=300)\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=[lat, lng],\n",
    "        radius=compute_radius(initial_zoom, count),\n",
    "        fill=True,\n",
    "        fill_opacity=0.7 / math.log(count + 2),\n",
    "        color=\"blue\",\n",
    "        fill_color=\"blue\",\n",
    "        popup=popup,\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "# Connect the dots with lines based on their order in the dataset\n",
    "# and update zoom opacity\n",
    "zoom_opacity_function = '''\n",
    "function updateOpacity(zoom) {\n",
    "    var opacity = (15 - zoom) / 15;\n",
    "    {% for line_id in line_ids %}\n",
    "        var line = document.getElementById('{{ line_id }}');\n",
    "        line.setAttribute('stroke-opacity', opacity);\n",
    "    {% endfor %}\n",
    "}\n",
    "\n",
    "map.on('zoomend', function() {\n",
    "    updateOpacity(map.getZoom());\n",
    "});\n",
    "'''\n",
    "\n",
    "line_ids = []  # Add this line to keep track of the line_ids\n",
    "\n",
    "unique_lines = set()\n",
    "for i in range(len(locations) - 1):\n",
    "    start_location = locations[i]\n",
    "    end_location = locations[i + 1]\n",
    "    \n",
    "    # Add the line only if it doesn't exist in the unique_lines set\n",
    "    if (start_location, end_location) not in unique_lines:\n",
    "        folium.PolyLine(\n",
    "            locations=[start_location, end_location],\n",
    "            color=\"green\",\n",
    "            weight=.5,\n",
    "        ).add_to(map)\n",
    "        \n",
    "        # Add the current line to the unique_lines set\n",
    "        unique_lines.add((start_location, end_location))\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map.save(\"most_active_locations.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
